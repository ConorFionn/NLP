{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz5oMTtGPiWZ"
      },
      "source": [
        "# Task 1\n",
        "**Class Food**\n",
        "\\begin{array}{|c|c|} \\hline\n",
        " & Truth: YES & Truth: NO \\\\ \\hline\n",
        "Classifier: YES & 800 & 200 \\\\\n",
        "Classifier: NO & 200 & 500 \\\\ \\hline\n",
        "\\end{array}\n",
        "\n",
        "**Class Drink**\n",
        "\\begin{array}{|c|c|} \\hline\n",
        " & Truth: YES & Truth: NO \\\\ \\hline\n",
        "Classifier: YES & 70 & 30 \\\\\n",
        "Classifier: NO & 30 & 100 \\\\ \\hline\n",
        "\\end{array}\n",
        "\n",
        "**a.** Microaveraged precision\n",
        "Need to create the Microaveraged precision table:\n",
        "\\begin{array}{|c|c|} \\hline\n",
        " & Truth: YES & Truth: NO \\\\ \\hline\n",
        "Classifier: YES & 870 & 230 \\\\\n",
        "Classifier: NO & 230 & 600 \\\\ \\hline\n",
        "\\end{array}\n",
        "\n",
        "$Microaveraged \\ Precision = \\frac{870}{870+230} = 0.79091 = $79.1%\n",
        "\n",
        "$Microaveraged \\ Recall = \\frac{870}{870+230} =$ 79.1%\n",
        "\n",
        "$Microaveraged \\ F1 = \\frac{2(0.791)(0.791)}{(0.791)+(0.791)}$\n",
        "\n",
        "$Macroaveraged \\ Precision = \\frac{0.8+0.7}{2} = 0.75 $ = 75%\n",
        "\n",
        "$Macroaveraged \\ Recall = \\frac{0.8+0.7}{2} =$ 75%\n",
        "\n",
        "$Macroaveraged \\ F1 = \\frac{2(0.75)(0.75)}{(0.75)+(0.75)} = 0.75$ = 75%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMXzNb-QA8VU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PDKnGsoA8XH",
        "outputId": "00d7e037-84f1-41b7-8543-50a36372ffad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "megaDocNEG=  just plain boring entirely predictable and lacks energy no surpises and very few laughs\n",
            "megaDocPOS=  very powerful the most fun film of the summer\n",
            "ProbNEG= 1.0\n",
            "ProbPOS= 0.0\n",
            "NEG_BOW =  {'just': 1, 'plain': 1, 'boring': 1, 'entirely': 1, 'predictable': 1, 'and': 2, 'lacks': 1, 'energy': 1, 'no': 1, 'surpises': 1, 'very': 1, 'few': 1, 'laughs': 1}\n",
            "POS_BOW =  {'very': 1, 'powerful': 1, 'the': 2, 'most': 1, 'fun': 1, 'film': 1, 'of': 1, 'summer': 1}\n",
            "V =  {'just': 1, 'plain': 1, 'boring': 1, 'entirely': 1, 'predictable': 1, 'and': 2, 'lacks': 1, 'energy': 1, 'no': 1, 'surpises': 1, 'very': 2, 'few': 1, 'laughs': 1, 'powerful': 1, 'the': 2, 'most': 1, 'fun': 1, 'film': 1, 'of': 1, 'summer': 1}\n",
            "|V| =  20\n",
            "Test document =  predictable with no fun\n",
            " word =  predictable    wordConditionalProbNEG =  0.06060606060606061    wordConditionalProbPOS =  0\n",
            "probNEGdoc=  0.06060606060606061 , probPOSdoc=  0.0\n",
            "Class inferred = NEG\n",
            "============================================================================\n",
            " word =  with    wordConditionalProbNEG =  0.030303030303030304    wordConditionalProbPOS =  0\n",
            "probNEGdoc=  0.0018365472910927458 , probPOSdoc=  0.0\n",
            "Class inferred = NEG\n",
            "============================================================================\n",
            " word =  no    wordConditionalProbNEG =  0.06060606060606061    wordConditionalProbPOS =  0\n",
            "probNEGdoc=  0.00011130589642986338 , probPOSdoc=  0.0\n",
            "Class inferred = NEG\n",
            "============================================================================\n",
            " word =  fun    wordConditionalProbNEG =  0.030303030303030304    wordConditionalProbPOS =  0.07142857142857142\n",
            "probNEGdoc=  3.3729059524201024e-06 , probPOSdoc=  0.0\n",
            "Class inferred = NEG\n",
            "============================================================================\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "import re\n",
        "import math\n",
        "from collections import Counter\n",
        "\n",
        "def naiveBayesClassifier(trainingset, testset):\n",
        "\n",
        "  # Blank list of all and POS class words\n",
        "  megaDocPOS = ''\n",
        "  megaDocNEG = ''\n",
        "\n",
        "  probNEGint=0\n",
        "  probPOSint=0\n",
        "  probNeut=0\n",
        "\n",
        "  # Casefolding both lists\n",
        "  train = [list(map(str.casefold, x)) for x in trainingset]\n",
        "  #print(train)\n",
        "\n",
        "  #this doesnt work for splitting sentence into individual words easily\n",
        "  #test = [list(map(str.casefold, x)) for x in testset]\n",
        "  #print(test)\n",
        "\n",
        "  testCase = []\n",
        "\n",
        "  for test in testset:\n",
        "    testCase.append((test[0]).casefold())\n",
        "\n",
        "  # Writing megadocs into blank class lists for POS and NEG\n",
        "  # Also interates an integer for calculating probability of NEG or POS class based on test\n",
        "\n",
        "\n",
        "  for i in range(len(train)):\n",
        "    if train[i][1] == '-':\n",
        "      tempNEG = train[i][0]\n",
        "      megaDocNEG = megaDocNEG + \" \" + tempNEG\n",
        "      probNEGint+=1\n",
        "    elif train[i][1] == '+':\n",
        "      tempPOS = train[i][0]\n",
        "      megaDocPOS = megaDocPOS + \" \" +  tempPOS\n",
        "      probNEGint+=1\n",
        "    else:\n",
        "      probNeut+=1\n",
        "\n",
        "\n",
        "  probTot=probPOSint+probNEGint\n",
        "  probNEG = (probNEGint/probTot)\n",
        "  probPOS = (probPOSint/probTot)\n",
        "\n",
        "  print(\"megaDocNEG=\", megaDocNEG)\n",
        "  print(\"megaDocPOS=\", megaDocPOS)\n",
        "\n",
        "  print(\"ProbNEG=\", probNEG)\n",
        "  print(\"ProbPOS=\", probPOS)\n",
        "\n",
        "  tokenNEG = megaDocNEG.split()\n",
        "  tokenPOS = megaDocPOS.split()\n",
        "\n",
        "  vocab = megaDocNEG + megaDocPOS\n",
        "  V = vocab.split()\n",
        "\n",
        "  NEGcount = Counter(tokenNEG)\n",
        "  POScount = Counter(tokenPOS)\n",
        "\n",
        "  Vcount = Counter(V)\n",
        "  #vTot = sum(Vcount.values())\n",
        "  vTot = len(Vcount)\n",
        "\n",
        "  NEGcount = dict(NEGcount)\n",
        "  POScount = dict(POScount)\n",
        "  Vcount = dict(Vcount)\n",
        "\n",
        "  NEGnum = len(NEGcount)\n",
        "  POSnum = len(POScount)\n",
        "\n",
        "  print(\"NEG_BOW = \", NEGcount)\n",
        "  print(\"POS_BOW = \", POScount)\n",
        "  print(\"V = \", Vcount)\n",
        "\n",
        "  print(\"|V| = \", vTot)\n",
        "\n",
        "  wordConditionalProbNEG = 0\n",
        "  wordConditionalProbPOS = 0\n",
        "\n",
        "  for test in testCase:\n",
        "    print(\"Test document = \", test)\n",
        "\n",
        "    probNEGdoc = probNEG\n",
        "    probPOSdoc = probPOS\n",
        "\n",
        "    for word in test.split():\n",
        "      if word in NEGcount:\n",
        "        wordConditionalProbNEG = (NEGcount[word] + 1) / (NEGnum + vTot)\n",
        "      else:\n",
        "        wordConditionalProbNEG = (0 + 1) / (NEGnum + vTot)\n",
        "      if word in POScount:\n",
        "        wordConditionalProbPOS = (POScount[word] + 1) / (POSnum + vTot)\n",
        "      else:\n",
        "        wordCondtionalProbPOS = (0 + 1) / (POSnum + vTot)\n",
        "\n",
        "      print(' word = ', word, '   wordConditionalProbNEG = ',wordConditionalProbNEG , '   wordConditionalProbPOS = ', wordConditionalProbPOS)\n",
        "\n",
        "      probNEGdoc = probNEGdoc * wordConditionalProbNEG\n",
        "      probPOSdoc = probPOSdoc * wordConditionalProbPOS\n",
        "\n",
        "      print('probNEGdoc= ', probNEGdoc, ', probPOSdoc= ', probPOSdoc)\n",
        "\n",
        "      if (math.isclose(probNEGdoc, probPOSdoc)):\n",
        "        print('Class inferred (close) = POS/NEG')\n",
        "\n",
        "      elif probPOSdoc > probNEGdoc:\n",
        "        print('Class inferred = POS')\n",
        "      elif probNEGdoc > probPOSdoc:\n",
        "        print('Class inferred = NEG')\n",
        "\n",
        "      print('============================================================================')\n",
        "\n",
        "  return\n",
        "\n",
        "trainingset = [('just plain boring', '-'),('entirely predictable and lacks energy', '-'),('no surpises and very few laughs', '-'),('very powerful', '+'),('the most fun film of the summer','+')]\n",
        "testset = [('Predictable with no fun', '?')]\n",
        "\n",
        "naiveBayesClassifier(trainingset, testset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzMW1EqWDwq5",
        "outputId": "2ba9b1b8-764b-4089-d10e-96f4ae50b77a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "String =  NLP is cool\n",
            "Sentiment(polarity=0.35, subjectivity=0.65)\n",
            "Sentinment is positive!\n",
            "0.35\n",
            "Subjectivity =  0.65\n",
            "---------------------------------------------------\n",
            "String =  NLP is cool and useful\n",
            "Sentiment(polarity=0.32499999999999996, subjectivity=0.325)\n",
            "Sentinment is positive!\n",
            "0.32499999999999996\n",
            "Subjectivity =  0.325\n",
            "---------------------------------------------------\n",
            "String =  NLP is hard\n",
            "Sentiment(polarity=-0.2916666666666667, subjectivity=0.5416666666666666)\n",
            "Sentinment is negative\n",
            "-0.2916666666666667\n",
            "Subjectivity =  0.5416666666666666\n",
            "---------------------------------------------------\n",
            "String =  NLP is hard and useless\n",
            "Sentiment(polarity=-0.39583333333333337, subjectivity=0.37083333333333335)\n",
            "Sentinment is negative\n",
            "-0.39583333333333337\n",
            "Subjectivity =  0.37083333333333335\n",
            "---------------------------------------------------\n",
            "String =  NLP stands for natural language processing\n",
            "Sentiment(polarity=0.1, subjectivity=0.4)\n",
            "Sentinment is positive!\n",
            "0.1\n",
            "Subjectivity =  0.4\n",
            "---------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "from textblob import TextBlob\n",
        "\n",
        "def sentimentAnalyzer(string):\n",
        "  testimonial = TextBlob(string)\n",
        "  print('String = ', string)\n",
        "  print(testimonial.sentiment)\n",
        "  if testimonial.sentiment.polarity > 0:\n",
        "      print('Sentinment is positive!')\n",
        "  elif testimonial.sentiment.polarity < 0:\n",
        "      print('Sentinment is negative')\n",
        "  else:\n",
        "    print('Sentinment is neutral')\n",
        "\n",
        "  print(testimonial.sentiment.polarity)\n",
        "  print('Subjectivity = ',testimonial.sentiment.subjectivity)\n",
        "  print('---------------------------------------------------')\n",
        "  return\n",
        "\n",
        "sentimentAnalyzer('NLP is cool')\n",
        "sentimentAnalyzer('NLP is cool and useful')\n",
        "sentimentAnalyzer('NLP is hard')\n",
        "sentimentAnalyzer('NLP is hard and useless')\n",
        "sentimentAnalyzer('NLP stands for natural language processing')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJVTiFMZIFC1"
      },
      "source": [
        "Task 4 & 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3icyQk8RCyVt",
        "outputId": "39c0bf0e-c6da-4c52-ca1f-f64fb6ef36b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training...\n",
            "\n",
            "Testing...\n",
            "Document:  ('University of Limerick', 'IE')\n",
            "Predicted Class:  IE\n",
            "Document:  ('University College Dublin', 'IE')\n",
            "Predicted Class:  IE\n",
            "Document:  ('Imperial College London', 'GB')\n",
            "Predicted Class:  GB\n",
            "Document:  ('University of Oxford', 'GB')\n",
            "Predicted Class:  GB\n",
            "Document:  ('Ireland & GB', 'GB')\n",
            "Predicted Class:  GB\n",
            "Accuracy:  1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from textblob.classifiers import NaiveBayesClassifier\n",
        "from textblob import TextBlob\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "def naiveBayesClassifier(trainingSet,testSet):\n",
        "    print(\"\\nTraining...\")\n",
        "    cl = NaiveBayesClassifier(trainingSet)\n",
        "    print(\"\\nTesting...\")\n",
        "    for sentence in testSet:\n",
        "      print(\"Document: \", sentence)\n",
        "      print(\"Predicted Class: \", cl.classify(sentence))\n",
        "\n",
        "    print(\"Accuracy: \", cl.accuracy(testSet))\n",
        "\n",
        "trainingSet = [('London is the Capital of GB','GB'),\n",
        "               ('Oxford is a city in GB','GB'),\n",
        "               ('Dublin is the capital of Ireland','IE'),\n",
        "               ('Limerick is a city in Ireland','IE')]\n",
        "testSet = [('University of Limerick','IE'),\n",
        "           ('University College Dublin','IE'),\n",
        "           ('Imperial College London','GB'),\n",
        "           ('University of Oxford','GB'),\n",
        "           ('Ireland & GB','GB')]\n",
        "\n",
        "\n",
        "naiveBayesClassifier(trainingSet,testSet)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7p2YMoDeH8qP",
        "outputId": "474f6c71-e4fe-4ed0-9a6c-c09e20f08df9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-28 11:12:51--  https://storage.googleapis.com/dataset-uploader/bbc/bbc-text.csv\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.214.128, 173.194.215.128, 173.194.216.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.214.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5057493 (4.8M) [text/csv]\n",
            "Saving to: ‘bbc-text.csv.4’\n",
            "\n",
            "\rbbc-text.csv.4        0%[                    ]       0  --.-KB/s               \rbbc-text.csv.4      100%[===================>]   4.82M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2022-11-28 11:12:51 (138 MB/s) - ‘bbc-text.csv.4’ saved [5057493/5057493]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://storage.googleapis.com/dataset-uploader/bbc/bbc-text.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xi88c0gCH_4Z",
        "outputId": "807b9271-0d7f-4775-e890-cac6ac6a4eec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           category                                               text\n",
            "0              tech  tv future in the hands of viewers with home th...\n",
            "1          business  worldcom boss  left books alone  former worldc...\n",
            "2             sport  tigers wary of farrell  gamble  leicester say ...\n",
            "3             sport  yeading face newcastle in fa cup premiership s...\n",
            "4     entertainment  ocean s twelve raids box office ocean s twelve...\n",
            "...             ...                                                ...\n",
            "2220       business  cars pull down us retail figures us retail sal...\n",
            "2221       politics  kilroy unveils immigration policy ex-chatshow ...\n",
            "2222  entertainment  rem announce new glasgow concert us band rem h...\n",
            "2223       politics  how political squabbles snowball it s become c...\n",
            "2224          sport  souness delight at euro progress boss graeme s...\n",
            "\n",
            "[2225 rows x 2 columns]\n",
            "Number of documents: 2225 \n",
            "\n",
            "category\n",
            "business         510\n",
            "entertainment    386\n",
            "politics         417\n",
            "sport            511\n",
            "tech             401\n",
            "dtype: int64 \n",
            "\n",
            "Training set examples: \n",
            "            category                                               text\n",
            "2017           tech  sony psp console hits us in march us gamers wi...\n",
            "1053  entertainment  black sabbath top rock album poll black sabbat...\n",
            "1438           tech  microsoft debuts security tools microsoft is r...\n",
            "1870          sport  jones doping probe begins an investigation int...\n",
            "1632          sport  edu blasts arsenal arsenal s brazilian midfiel...\n",
            "...             ...                                                ...\n",
            "664   entertainment  no uk premiere for rings musical the producers...\n",
            "115   entertainment  byrds producer melcher dies at 62 record produ...\n",
            "1683       business  five million germans out of work germany s une...\n",
            "985           sport  cup holders man utd visit everton holders manc...\n",
            "64         business  india power shares jump on debut shares in ind...\n",
            "\n",
            "[1780 rows x 2 columns]\n",
            "Testing set examples: \n",
            "            category                                               text\n",
            "1325           tech  ask jeeves joins web log market ask jeeves has...\n",
            "676        business  ukraine steel sell-off  illegal  the controver...\n",
            "729           sport  mansfield 0-1 leyton orient an second-half goa...\n",
            "907        politics  butler launches attack on blair former civil s...\n",
            "902            tech  mobiles  not media players yet  mobiles are no...\n",
            "...             ...                                                ...\n",
            "717        politics  child access laws shake-up parents who refuse ...\n",
            "450        politics  labour in constituency race row labour s choic...\n",
            "865   entertainment  brits debate over  urban  music joss stone  a ...\n",
            "1635       politics  super union  merger plan touted two of britain...\n",
            "1734           tech  disney backs sony dvd technology a next genera...\n",
            "\n",
            "[445 rows x 2 columns]\n",
            "\n",
            "Training...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from csv import reader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv('bbc-text.csv')\n",
        "print(df)\n",
        "\n",
        "print('Number of documents:', len(df),'\\n')\n",
        "\n",
        "print(df.groupby(['category']).size(),'\\n')\n",
        "\n",
        "train, test = train_test_split(df, test_size=0.2)\n",
        "\n",
        "print(\"Training set examples: \\n\", train)\n",
        "\n",
        "print(\"Testing set examples: \\n\", test)\n",
        "\n",
        "train = list(zip(df['text'], df['category']))\n",
        "\n",
        "print(\"\\nTraining...\")\n",
        "cl = NaiveBayesClassifier(train)\n",
        "\n",
        "for i in range(len(test)):\n",
        "  state = cl.classify(test[i])\n",
        "  i+=1\n",
        "accuracy = cl.accuracy(test)\n",
        "print('Accuracy: ', accuracy)\n",
        "\n",
        "print(\"\\nTesting...\")\n",
        "\n",
        "df = pd.DataFrame(train)\n",
        "dg = pd.DataFrame(test)\n",
        "\n",
        "train = df.values.tolist()\n",
        "test = dg.values.tolist()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}